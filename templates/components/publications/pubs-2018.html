<div class="row">
    <div class="col-md-3" style="margin-top: 25px;">
        <img src="/static/picture/NIPS18-Qi-et-al-Bandit-Learning-with-Implicit-Feedback.png" width="240">
    </div>
    <div class="col-md-9">
        <div class="pubs-title">
            <b>Bandit Learning with Implicit Feedback.</b>
            [<a href="http://lfs.aminer.cn/misc/moocdata/publications/NIPS18-Qi-et-al-Bandit-Learning-with-Implicit-Feedback.pdf" target="_blank">PDF</a>]
            [<a href="/data/xiaomu-question">Data</a>]
        </div>
        <div class="pubs-author">
            Yi Qi, Qingyun Wu, Hongning Wang, Jie Tang, and Maosong Sun.
        </div>
        <div class="pubs-conf">
            In <a href="https://nips.cc/Conferences/2018/" target="_blank"><i>Proceedings of the Thirty-Second Annual Conference on Neural Information Processing Systems</i></a>
            (<a href="https://nips.cc/Conferences/2018/" target="_blank">NeurIPS'18</a>).
        </div>
        <p class="pubs-abstract">
            Implicit feedback, such as user clicks, although abundant in online information service systems, does not provide substantial evidence on users' evaluation of system's output. Such incomplete supervision inevitably misleads model estimation, especially in a bandit learning setting where the feedback is acquired on the fly. In this work, we study a contextual bandit problem with implicit feedback by modeling the feedback as a composition of user result examination and relevance judgment. Since users' examination behavior is unobserved, we introduce latent variables to model it. We perform Thompson sampling on top of variational Bayesian inference for arm selection and model update. Rigorous upper regret bound analysis of the proposed algorithm proves its feasibility of learning from implicit feedback; and extensive empirical evaluations on click logs collected from a major MOOC platform further demonstrate its learning effectiveness in practice.
        </p>
    </div>
</div>